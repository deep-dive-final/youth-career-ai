import os
import asyncio
import time
from openai import AsyncOpenAI
from google import genai
from google.genai import types
from utils.db import getMongoDbClient
from tavily import TavilyClient  # Tavily ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

from dotenv import load_dotenv
load_dotenv()

openai_client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
gemini_client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))
# Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
tavily_client = TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))

async def get_query_vector_async(text):
    loop = asyncio.get_event_loop()
    res = await loop.run_in_executor(None, lambda: gemini_client.models.embed_content(
        model="gemini-embedding-001",
        contents=text,
        config=types.EmbedContentConfig(task_type="RETRIEVAL_QUERY")
    ))
    return res.embeddings[0].values

async def get_AI_response(messages):
    overall_start = time.time()
    user_query = messages[-1]['content']
    
    # --- 1. GPT-4oë¥¼ ì´ìš©í•œ ë‹¤ì¤‘ ì§€ì—­ëª… ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ---
    try:
        # ì •ì±… ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ì™€ ì§€ì—­ëª…ì„ ë™ì‹œì— íŒë‹¨í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ê³ ë„í™”
        intent_region_prompt = [
            {"role": "system", "content": """
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ 'ì •ë¶€/ì§€ìì²´ ì •ì±…, ì·¨ì—… ì§€ì›, ë³µì§€, ìˆ˜ë‹¹' ë“± ì •ì±… ìƒë‹´ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ê³  ì§€ì—­ëª…ì„ ì¶”ì¶œí•˜ì„¸ìš”.
            ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
            {
              "is_policy": true ë˜ëŠ” false,
              "regions": "ì¶”ì¶œëœ ì§€ì—­ëª…ë“¤ (ì˜ˆ: ê²½ê¸°, ì•ˆì‚° / ì§€ì—­ ì—†ìœ¼ë©´ 'ì „êµ­')",
              "reason": "íŒë‹¨ ì´ìœ "
            }
            """},
            {"role": "user", "content": user_query}
        ]
        
        intent_res = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=intent_region_prompt,
            response_format={"type": "json_object"} # JSON ì¶œë ¥ ê°•ì œ
        )
        
        import json
        analysis = json.loads(intent_res.choices[0].message.content)
        
        # [ì²´í¬] ì •ì±… ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹ˆë¼ê³  íŒë‹¨ë˜ë©´ ì¦‰ì‹œ ìš°íšŒ ë‹µë³€ ë°˜í™˜
        if not analysis.get("is_policy", True):
            return f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì²­ë…„ ì •ì±… ë° ì·¨ì—… ì§€ì› ì •ë³´ë¥¼ ì•ˆë‚´í•´ ë“œë¦¬ëŠ” ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. í˜„ì¬ ì§ˆë¬¸í•˜ì‹  '{user_query}' ë‚´ìš©ì€ ì •ì±… ìƒë‹´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ ë‹µë³€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì§€ì›ê¸ˆ, ì·¨ì—… í˜œíƒ ë“± ì •ì±…ì— ëŒ€í•´ ë¬¼ì–´ë´ ì£¼ì‹œë©´ ìì„¸íˆ ì•ˆë‚´í•´ ë“œë¦´ê²Œìš”! ğŸ˜Š"

        # [ì§€ì—­ ì¶”ì¶œ] ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ ì§€ì—­ëª… ë¦¬ìŠ¤íŠ¸ ë³€í™˜
        raw_regions = analysis.get("regions", "ì „êµ­").split(',')
        target_regions = [r.strip().replace("ì‹œ", "").replace("ë„", "") for r in raw_regions if "ì „êµ­" not in r]
        
    except Exception as e:
        print(f"ì˜ë„ íŒë³„ ì˜¤ë¥˜: {e}")
        target_regions = [] # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€

    # --- 2. RAG ë°ì´í„° ê²€ìƒ‰ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨í•˜ë„ë¡ ìˆ˜ì •) ---
    query_vector = await get_query_vector_async(user_query)
    db = getMongoDbClient()
    vector_results = list(db['policy_vectors'].aggregate([
        {"$vectorSearch": {
            "index": "vector_index_v2", 
            "path": "embedding_gemini_v2", 
            "queryVector": query_vector, 
            "numCandidates": 100, 
            "limit": 30 
        }},
        {"$addFields": {"score": {"$meta": "vectorSearchScore"}}}  # ì¶©ë¶„ì„± íŒë‹¨ì„ ìœ„í•œ ì ìˆ˜ ì¶”ê°€
    ]))

    # --- [ì‹ ê·œ] 3. ê²€ìƒ‰ ê²°ê³¼ ì¶©ë¶„ì„± íŒë‹¨ ë° ì™¸ë¶€ ê²€ìƒ‰ (Fallback) ---
    # ìµœê³  ì ìˆ˜ê°€ 0.7 ë¯¸ë§Œì´ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì™¸ë¶€ ê²€ìƒ‰ ì‹¤í–‰
    max_score = vector_results[0].get('score', 0) if vector_results else 0
    is_sufficient = max_score >= 0.7 
    
    external_data = []
    if not is_sufficient:
        print(f"âš ï¸ ë‚´ë¶€ ë°ì´í„° ì ìˆ˜ ë¶€ì¡± ({max_score:.2f}). ì™¸ë¶€ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        # ì •ì±… ê´€ë ¨ ë„ë©”ì¸(gov.kr)ìœ¼ë¡œ ì œí•œí•˜ì—¬ ê²€ìƒ‰
        search_query = f"site:gov.kr {', '.join(target_regions) if target_regions else ''} {user_query}"
        try:
            # Tavily ì‹¤ì‹œê°„ ê²€ìƒ‰ ìˆ˜í–‰
            web_search = await asyncio.to_thread(
                tavily_client.search, query=search_query, search_depth="advanced"
            )
            external_data = web_search.get('results', [])
        except Exception as e:
            print(f"ì™¸ë¶€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    # --- 4. ë°ì´í„° í•„í„°ë§ ë° ë§¤ì¹­ (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ---
    region_specific, nationwide = [], []
    seen_titles = set()

    for doc in vector_results:
        meta = doc.get('metadata', {})
        title = meta.get('policy_name', '').strip()
        region_val = meta.get('region', ['ì „êµ­'])[0]
        
        if title in seen_titles: continue
        
        item = {
            "title": title, 
            "region": region_val, 
            "content": doc.get('content_chunk_v2') or meta.get('support_content')
        }

        is_match = any(reg in region_val or reg in title for reg in target_regions)

        if target_regions and is_match:
            region_specific.append(item)
        elif any(k in region_val for k in ["ì „êµ­", "ì¤‘ì•™", "êµ­ê°€"]):
            nationwide.append(item)
        
        seen_titles.add(title)

    top_5 = (region_specific + nationwide)[:5]
    context_status = ", ".join(target_regions) if region_specific else "ì „êµ­"

    # --- 5. ì¡°ê±´ë¶€ ë‹µë³€ ìƒì„± (ë°ì´í„° ê²€ì¦ ë° ì¶œì²˜ ë¶„ê¸°) ---
    
    # [ì¶”ê°€] ë‚´ë¶€ ë°ì´í„° ì ìˆ˜ê°€ ë†’ë”ë¼ë„, ì‹¤ì œ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ GPTê°€ ìµœì¢… ê²€ì¦ (ë¦¬ë­í‚¹ ëŒ€ìš©)
    if is_sufficient:
        verification_prompt = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„±ì„ íŒë‹¨í•˜ëŠ” í‰ê°€ê´€ì…ë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ë°ì´í„°ê°€ ê´€ë ¨ì´ ìˆìœ¼ë©´ 'YES', ê´€ë ¨ì´ ì—†ê±°ë‚˜ ì§ˆë¬¸ì˜ íŠ¹ì • ê³ ìœ ëª…ì‚¬(ì •ì±…ëª… ë“±)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ 'NO'ë¼ê³ ë§Œ ë‹µí•˜ì„¸ìš”."},
            {"role": "user", "content": f"ì§ˆë¬¸: {user_query}\në°ì´í„° ìš”ì•½: {[d['title'] for d in top_5]}\n\nê´€ë ¨ì´ ìˆìŠµë‹ˆê¹Œ?"}
        ]
        try:
            v_res = await openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=verification_prompt,
                max_tokens=5,
                temperature=0
            )
            is_valid = v_res.choices[0].message.content.strip().upper()
            if "NO" in is_valid:
                print(f"âš ï¸ [ê²€ì¦ ì‹¤íŒ¨] ì ìˆ˜ëŠ” ë†’ìœ¼ë‚˜({max_score:.2f}) ì§ˆë¬¸ê³¼ ë‚´ìš©ì´ ë¶ˆì¼ì¹˜í•©ë‹ˆë‹¤. ì™¸ë¶€ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                is_sufficient = False # ê°•ì œë¡œ ë¶€ì¡± ìƒíƒœë¡œ ì „í™˜í•˜ì—¬ ì™¸ë¶€ ê²€ìƒ‰ ì‹¤í–‰
                
                # ì™¸ë¶€ ê²€ìƒ‰ì´ ì•„ì§ ì•ˆ ë˜ì—ˆë‹¤ë©´ ì‹¤í–‰ (Tavily ì¬í˜¸ì¶œ)
                if not external_data:
                    search_query = f"site:gov.kr {', '.join(target_regions) if target_regions else ''} {user_query}"
                    web_search = await asyncio.to_thread(tavily_client.search, query=search_query, search_depth="advanced")
                    external_data = web_search.get('results', [])
        except:
            pass # ê²€ì¦ ì—ëŸ¬ ì‹œ ê¸°ì¡´ ì ìˆ˜ ê¸°ì¤€ ìœ ì§€

    # ìµœì¢… ë¶„ê¸° ì²˜ë¦¬
    if not is_sufficient and external_data:
        source_info = "ì •ë¶€24 ë° ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰"
        data_to_use = external_data
        # ë‹µë³€ ëì— ì¶œì²˜ë¥¼ ë¶™ì´ë˜, ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        system_instruction = f"""
        ë‚´ë¶€ DBì— ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ {source_info} ê²°ê³¼ë¥¼ ì°¸ê³ í•©ë‹ˆë‹¤. 
        ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ì—ì„œë„ ì‚¬ìš©ìê°€ ì°¾ëŠ” íŠ¹ì • ì •ì±…ëª…ì´ ëª…í™•íˆ í™•ì¸ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´, 
        ì–µì§€ë¡œ ë‹µë³€í•˜ì§€ ë§ê³  'ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤'ê³  ì •ì¤‘íˆ ì•ˆë‚´í•˜ì„¸ìš”.
        ë‹µë³€ ëì—ëŠ” ë°˜ë“œì‹œ [ì¶œì²˜: {source_info}]ë¥¼ í•œ ì¤„ ë„ìš°ê³  ì ì–´ì£¼ì„¸ìš”.
        """
    elif not is_sufficient and not external_data:
        # ì´ êµ¬ê°„ì€ ì¶œì²˜ ì—†ì´ ê¹”ë”í•˜ê²Œ ì•ˆë‚´ë§Œ ë‚˜ê°‘ë‹ˆë‹¤.
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë‚´ë¶€ DB ë° ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ í†µí•´ì„œë„ í•´ë‹¹ ì •ì±…ì— ëŒ€í•œ ì •í™•í•œ ì •ë³´ë¥¼ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì •ì±…ëª…ì´ë‚˜ ì§€ì—­ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ğŸ˜Š"
    else:
        data_to_use = top_5
        system_instruction = f"ë‹¹ì‹ ì€ {context_status} ì •ì±… ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë³„ë„ì˜ ì¶œì²˜ ë¬¸êµ¬ëŠ” ì ì§€ ë§ˆì„¸ìš”."

    api_messages = [
        {"role": "system", "content": system_instruction},
        {"role": "user", "content": f"[ì°¸ê³  ë°ì´í„°]\n{data_to_use}\n\nì§ˆë¬¸: {user_query}\n\nìœ„ ë°ì´í„° ì¤‘ ê°€ì¥ ì í•©í•œ 2ê°œë¥¼ ê³¨ë¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n### [ì •ì±…ëª…]\n* ğŸ‘¤ ëŒ€ìƒ: ì¡°ê±´\n* ğŸ í˜œíƒ: ìƒì„¸ë‚´ìš©\n* ğŸ“… ì‹ ì²­: ë°©ë²•"}
    ]

    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=api_messages,
            max_completion_tokens=2000,
            temperature=0.7
        )
        ai_answer = response.choices[0].message.content
    except Exception as e:
        ai_answer = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    # --- 6. ì…€í”„ ë¦¬í”Œë ‰ì…˜ (ë‹µë³€ ê²€í† ) ---
    reflection_prompt = f"""
    ë‹¹ì‹ ì€ ì •ì±… ë‹µë³€ ê²€ì¦ê´€ì…ë‹ˆë‹¤. ì•„ë˜ [ìƒì„±ëœ ë‹µë³€]ì´ [ì°¸ê³  ë°ì´í„°]ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
    
    [ì°¸ê³  ë°ì´í„°]: {data_to_use}
    [ìƒì„±ëœ ë‹µë³€]: {ai_answer}
    
    í™•ì¸ ê¸°ì¤€:
    1. ë°ì´í„°ì— ì—†ëŠ” ì •ì±…ì„ ì§€ì–´ëƒˆëŠ”ê°€? (í™˜ê° í™•ì¸)
    2. ì‹ ì²­ ëŒ€ìƒì´ë‚˜ í˜œíƒ ê¸ˆì•¡ì´ ë°ì´í„°ì™€ ë‹¤ë¥¸ê°€?
    
    ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´ 'ìˆ˜ì •ëœ ë‚´ìš©'ë§Œ ì¶œë ¥í•˜ê³ , ë¬¸ì œê°€ ì—†ë‹¤ë©´ [ìƒì„±ëœ ë‹µë³€]ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”. 
    'ìˆ˜ì •ëœ ë‹µë³€:' ì´ë¼ëŠ” ë¨¸ë¦¿ë§ì´ë‚˜ ê²€í†  ê²°ê³¼ì— ëŒ€í•œ ë¶€ì—° ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    """

    try:
        # ì†ë„ë¥¼ ìœ„í•´ 4o-mini ëª¨ë¸ ì‚¬ìš©
        reflection_response = await openai_client.chat.completions.create(
            model="gpt-4o-mini", 
            messages=[{"role": "system", "content": reflection_prompt}],
            temperature=0
        )
        final_answer = reflection_response.choices[0].message.content
    except Exception:
        final_answer = ai_answer  # ì˜¤ë¥˜ ì‹œ ì›ë˜ ë‹µë³€ ìœ ì§€
    
    # ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„ ë§ˆì§€ë§‰ì— ë¡œê·¸ ì¶œë ¥
    print(f"\nğŸ“Š [ë¶„ì„] ì¶”ì¶œì§€ì—­: {context_status} | ì ìˆ˜: {max_score:.4f} | ê²€ì¦: {'í†µê³¼' if is_sufficient else 'ì‹¤íŒ¨(Fallback)'} | ì „ì²´ì‹œê°„: {time.time()-overall_start:.2f}s")
    
    return final_answer # ê²€í† ê°€ ì™„ë£Œëœ ìµœì¢… ë‹µë³€ ë°˜í™˜
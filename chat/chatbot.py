import os
import numpy as np
from google import genai
from google.genai import types
from utils.db import getMongoDbClient  

from dotenv import load_dotenv
load_dotenv()

# 1. ì´ˆê¸° ì„¤ì •
API_KEY = os.getenv('GEMINI_API_KEY')
client = genai.Client(api_key=API_KEY)

def get_query_vector(text):
    """3072ì°¨ì› ì„ë² ë”© ì¶”ì¶œ (gemini-embedding-001)"""
    res = client.models.embed_content(
        model="gemini-embedding-001",
        contents=text,
        config=types.EmbedContentConfig(task_type="RETRIEVAL_QUERY")
    )
    return res.embeddings[0].values

def get_AI_response(messages):
    """
    views.pyì—ì„œ ì „ë‹¬ë°›ì€ messages(ëŒ€í™” ë‚´ì—­)ë¥¼ ë°”íƒ•ìœ¼ë¡œ RAG ë‹µë³€ ìƒì„±
    """
    print("[get_AI_response] start RAG process...")

    # 1. ë§ˆì§€ë§‰ ì§ˆë¬¸ ì¶”ì¶œ
    user_query = messages[-1]['content']
    
    # 2. ì§ˆë¬¸ ë²¡í„°í™”
    query_vector = get_query_vector(user_query)
    
    # 3. MongoDB ë²¡í„° ê²€ìƒ‰ 
    db = getMongoDbClient()
    vector_results = list(db['policy_vectors'].aggregate([
        {
            "$vectorSearch": {
                "index": "vector_index_v2",
                "path": "embedding_gemini_v2",
                "queryVector": query_vector,
                "numCandidates": 100,
                "limit": 10
            }
        },
        {
            "$lookup": {
                "from": "policies",
                "localField": "policy_id",
                "foreignField": "_id",
                "as": "policy_detail"
            }
        },
        { "$unwind": "$policy_detail" }
    ]))

    # 4. ê²€ìƒ‰ëœ ì •ì±… ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    candidate_context = ""
    for i, doc in enumerate(vector_results):
        detail = doc.get('policy_detail', {})
        agency = detail.get('supervising_agency', 'ì •ë³´ ì—†ìŒ')
        title = detail.get('title', 'ì œëª© ì—†ìŒ')
        content = detail.get('content_chunk_v2', str(detail)[:500])
        candidate_context += f"[{i}] ê¸°ê´€: {agency} | ì œëª©: {title} | ë‚´ìš©: {content}\n"

    # 5. ì´ì „ ëŒ€í™” ìš”ì•½ (ìµœê·¼ 3ê°œ)
    history_text = ""
    for msg in messages[:-1][-3:]:
        role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
        history_text += f"{role}: {msg['content']}\n\n"

    # 6. í”„ë¡¬í”„íŠ¸ ì ìš©
    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì²­ë…„ ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì´ë‚˜ ì„œë¡ ("ì˜ë„ë¥¼ íŒŒì•…í–ˆìŠµë‹ˆë‹¤" ë“±)ì€ ìƒëµí•˜ê³  ë°”ë¡œ ë³¸ë¡ ë§Œ ë‹µë³€í•˜ì„¸ìš”.

    [ì´ì „ ëŒ€í™”]:
    {history_text if history_text else "ì´ì „ ëŒ€í™” ì—†ìŒ"}

    [ìƒˆë¡œ ê²€ìƒ‰ëœ ì •ì±… í›„ë³´]:
    {candidate_context}

    [ë‹µë³€ ê°€ì´ë“œë¼ì¸]:
    **CASE A: ìƒˆë¡œìš´ ì •ì±… ì¶”ì²œì„ ì›í•˜ëŠ” ê²½ìš° (ì˜ˆ: "ì·¨ì—… ì •ì±… ì•Œë ¤ì¤˜", "ì•ˆì‚° ì •ì±… ìˆì–´?")**
    1. [ìƒˆë¡œ ê²€ìƒ‰ëœ ì •ì±… í›„ë³´] ì¤‘ ê°€ì¥ ì í•©í•œ ê²ƒì„ 2ê°œ ì´ë‚´ë¡œ ì„ ë³„í•˜ì„¸ìš”.
    2. ì§€ì—­(ì•ˆì‚° ë“±)ì´ ë§ìœ¼ë©´ [ì§€ì—­ íŠ¹í™”], êµ­ê°€ ì‚¬ì—…ì´ë©´ [ğŸš©êµ­ê°€ ì§€ì›] ê¼¬ë¦¬í‘œë¥¼ ë¶™ì´ì„¸ìš”.
    3. ì•„ë˜ í¬ë§·ì„ ìœ ì§€í•˜ì„¸ìš”:
       ### [ì •ì±…ëª…]
       * ğŸ‘¥ **ëŒ€ìƒ**: í•µì‹¬ë§Œ 1ì¤„
       * ğŸ **í˜œíƒ**: í•µì‹¬ë§Œ 1ì¤„
       * ğŸ“… **ì‹ ì²­**: ê°„ëµíˆ
       ---

    **CASE B: ì´ì „ ë‹µë³€ ë‚´ìš©ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•˜ëŠ” ê²½ìš° (ì˜ˆ: "2ë²ˆì§¸ ê±° ìì„¸íˆ", "ì‹ ì²­ ì„œë¥˜ ë­ì•¼?")**
    1. ìƒˆë¡œ ê²€ìƒ‰ëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë³´ë‹¤ [ì´ì „ ëŒ€í™”]ì— ì–¸ê¸‰ëœ íŠ¹ì • ì •ì±…ì˜ ë‚´ìš©ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì„¸ìš”.
    2. "2ë²ˆì§¸ ì •ì±…"ê³¼ ê°™ì´ ìˆ«ìë¡œ ì§€ì¹­í•˜ë©´, ì´ì „ ëŒ€í™” ë¦¬ìŠ¤íŠ¸ì˜ ìˆœì„œë¥¼ í™•ì¸í•˜ì—¬ ì •í™•í•œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.
    3. 'ì‹ ì²­ í”„ë¡œì„¸ìŠ¤', 'í•„ìš” ì„œë¥˜', 'ì£¼ì˜ì‚¬í•­' ë“±ì„ ì¹œì ˆí•˜ê²Œ ë³´ì¶© ì„¤ëª…í•˜ì„¸ìš”.
    4. ìƒˆë¡œìš´ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ë‚˜ì—´í•˜ì§€ ë§ˆì„¸ìš”.

    **ê³µí†µ ì£¼ì˜ì‚¬í•­**:
    - íƒ€ ì§€ì—­(ê±°ì£¼ì§€ì™€ ë¬´ê´€í•œ ê³³) ì •ì±…ì€ ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”.
    - ë‹µë³€ì€ ìµœëŒ€í•œ ê°„ê²°í•˜ê³  ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
    """

    # 7. Gemini 3 Flash ë‹µë³€ ìƒì„±
    response = client.models.generate_content(
        model="gemini-3-flash-preview", 
        contents=prompt
    )
    
    return response.text
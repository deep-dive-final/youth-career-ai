"""
ë§ì¶¤ì •ì±… ê²€ìƒ‰ ì„œë¹„ìŠ¤
- Gemini AI ì„ë² ë”©ì„ ì´ìš©í•œ ì‹œë§¨í‹± ê²€ìƒ‰
- MongoDB Vector Searchë¥¼ ì´ìš©í•œ ì •ì±… ë§¤ì¹­
"""

import os
import re
from datetime import date
from google import genai
from utils.db import getMongoDbClient
from django.conf import settings

# ============================================================================
# ìƒìˆ˜
# ============================================================================

SCORE_THRESHOLD = 0.855  # ë²¡í„° ìœ ì‚¬ë„ ì„ê³„ê°’ (0.855 ë¯¸ë§Œì€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œì™¸)
AMOUNT_TEXT_RE = re.compile(
    r"(?:ì›”|ì—°|ìµœëŒ€|ìµœì†Œ)?\s*\d[\d,]*(?:\s*[~\-]\s*\d[\d,]*)?\s*(?:ì–µ|ë§Œì›|ì²œì›|ì›)"
)
SUMMARY_SENTENCE_SPLIT_RE = re.compile(r"[.!?]\s+|\n+")


# ============================================================================
# 1ï¸âƒ£ Gemini AI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# ============================================================================

def get_genai_client():
    """
    Gemini API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” Django ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        api_key = getattr(settings, "GEMINI_API_KEY", None)
    if not api_key:
        api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        api_key = getattr(settings, "GOOGLE_API_KEY", None)

    if not api_key:
        raise ValueError("GEMINI_API_KEY or GOOGLE_API_KEY not found.")

    return genai.Client(api_key=api_key)


def _to_int_or_none(value):
    """
    ìˆ«ì/ë¬¸ì ê°’ì„ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ë³€í™˜ ë¶ˆê°€/ë¹ˆê°’ì€ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if value is None:
        return None

    raw = str(value).strip().replace(",", "")
    if raw == "":
        return None

    try:
        return int(float(raw))
    except (TypeError, ValueError):
        return None


def _format_money(value: int):
    return f"{value:,}ì›"


def _extract_amount_text(*texts):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ê¸ˆì•¡ íŒ¨í„´(ë§Œì›/ì› ë“±)ì„ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    for text in texts:
        if not text:
            continue
        match = AMOUNT_TEXT_RE.search(str(text))
        if match:
            return " ".join(match.group(0).split())
    return None


def _query_terms(query: str):
    """
    ì¿¼ë¦¬ì—ì„œ ì˜ë¯¸ ìˆëŠ” í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if not query:
        return []
    terms = []
    for token in re.findall(r"[0-9A-Za-zê°€-í£]+", str(query).lower()):
        if len(token) >= 2:
            terms.append(token)
    return terms


def _normalize_text(value):
    if not value:
        return ""
    return " ".join(str(value).replace("\u00a0", " ").split())


def _extractive_summary(text: str, terms: list[str]):
    """
    ê°„ë‹¨í•œ ì¶”ì¶œí˜• ìš”ì•½:
    - ì¿¼ë¦¬ í† í°/ê¸ˆì•¡ íŒ¨í„´ì´ í¬í•¨ëœ ë¬¸ì¥ì„ ìš°ì„  ì„ íƒ
    - ì—†ìœ¼ë©´ ì²« ë¬¸ì¥ ì‚¬ìš©
    """
    normalized = _normalize_text(text)
    if not normalized:
        return None

    raw_sentences = [s.strip() for s in SUMMARY_SENTENCE_SPLIT_RE.split(normalized)]
    sentences = [s for s in raw_sentences if len(s) >= 8]
    if not sentences:
        return normalized[:180]

    best_idx = 0
    best_score = -1
    terms_lower = [t.lower() for t in terms]

    for idx, sentence in enumerate(sentences):
        sentence_lower = sentence.lower()
        score = 0
        if terms_lower:
            score += sum(1 for t in terms_lower if t in sentence_lower)
        if AMOUNT_TEXT_RE.search(sentence):
            score += 1
        if score > best_score:
            best_score = score
            best_idx = idx

    summary = sentences[best_idx]
    if best_idx + 1 < len(sentences):
        next_sentence = sentences[best_idx + 1]
        if len(summary) + len(next_sentence) <= 180:
            summary = f"{summary}. {next_sentence}"

    return summary[:220]


def _build_summary_text(policy: dict, terms: list[str]):
    """
    ìš”ì•½ ìš°ì„ ìˆœìœ„:
    policy_summary -> content_chunk_v3 -> support_content -> content
    """
    candidates = [
        policy.get("policy_summary"),
        policy.get("content_chunk_v3"),
        policy.get("support_content"),
        policy.get("content"),
    ]

    for candidate in candidates:
        summary = _extractive_summary(candidate, terms)
        if summary:
            return summary

    return None


def _build_amount_text(policy: dict):
    """
    ê¸ˆì•¡ í‘œê¸° ê·œì¹™:
    - max > 0: min > 0ì´ë©´ range, ì•„ë‹ˆë©´ ìµœëŒ€
    - max == 0 and min > 0: ìµœì†Œ
    - min == 0 and max == 0: ë¯¸í‘œì‹œ
    - min/max ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œì‹ ì¶”ì¶œ
    """
    earn = policy.get("earn") or {}
    min_amt = _to_int_or_none(earn.get("min_amt"))
    max_amt = _to_int_or_none(earn.get("max_amt"))

    if max_amt is not None:
        if max_amt > 0:
            if min_amt is not None and min_amt > 0:
                return f"{_format_money(min_amt)} ~ {_format_money(max_amt)}"
            return f"ìµœëŒ€ {_format_money(max_amt)}"

        if max_amt == 0:
            if min_amt is not None and min_amt > 0:
                return f"ìµœì†Œ {_format_money(min_amt)}"
            return None

    if min_amt is not None and min_amt > 0:
        return f"ìµœì†Œ {_format_money(min_amt)}"

    return _extract_amount_text(
        earn.get("etc_content"),
        policy.get("support_content"),
    )


def _enrich_policy_item(item: dict):
    """
    í”„ë¡ íŠ¸/í‰ê°€ ê³µí†µ ì‚¬ìš© í•„ë“œ(doc_id, amount_text, summary_text)ë¥¼ ë³´ê°•í•©ë‹ˆë‹¤.
    """
    if "_id" in item and "doc_id" not in item:
        item["doc_id"] = str(item.pop("_id"))
    elif "doc_id" in item:
        item["doc_id"] = str(item["doc_id"])

    item["amount_text"] = _build_amount_text(item)
    item["summary_text"] = _build_summary_text(item, item.get("_query_terms", []))
    item.pop("_query_terms", None)
    item.pop("policy_summary", None)
    item.pop("content_chunk_v3", None)
    item.pop("content", None)
    return item


# ============================================================================
# 2ï¸âƒ£ í•„í„° ì¡°ê±´ ìƒì„± í•¨ìˆ˜ë“¤
# ============================================================================


def _build_policy_match(filters: dict | None):
    """
    ì‚¬ìš©ìê°€ ì„ íƒí•œ í•„í„°ë¥¼ MongoDB ì¿¼ë¦¬ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    [DB ë¶„ì„ ê¸°ë°˜ í•„ë“œ ë§¤í•‘]
    - ì§€ì—­        : region (ìµœìƒìœ„ list, 858ê°œ ì „ë¶€ ì±„ì›Œì§)
    - ì§ì—…ìƒíƒœ    : job_type (ìµœìƒìœ„ list, 858ê°œ ì „ë¶€ ì±„ì›Œì§)
    - ë‚˜ì´        : eligibility.age_min / age_max (str íƒ€ì…, '0'='ì œí•œì—†ìŒ')
    - ì¹´í…Œê³ ë¦¬    : category (regex, ì½¤ë§ˆ êµ¬ë¶„ ê°€ëŠ¥)
    - ë§ˆê°ì—¬ë¶€    : dates.apply_period (ì—†ìœ¼ë©´ ìƒì‹œëª¨ì§‘ìœ¼ë¡œ ê°„ì£¼)
    """
    if not filters:
        return {}

    conditions = []

    # â”€â”€ ì¹´í…Œê³ ë¦¬ (category - regex, ì½¤ë§ˆ í˜¼ìš© ì²˜ë¦¬) â”€â”€â”€â”€â”€â”€â”€â”€
    category = filters.get("category")
    if category and category != "all":
        conditions.append({
            "category": {"$regex": category, "$options": "i"}
        })

    # â”€â”€ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ (sub_category - ì •í™•í•œ ì¼ì¹˜ ë˜ëŠ” regex) â”€â”€â”€â”€â”€â”€â”€â”€
    sub_category = filters.get("sub_category")
    if sub_category and sub_category != "all":
        conditions.append({
            "sub_category": sub_category
        })

    # â”€â”€ ê°œì¸ ì¡°ê±´ í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # ë‚˜ì´ (eligibility.age_min/max ëŠ” str íƒ€ì…ì´ë¯€ë¡œ ìˆ«ì ë¹„êµëŠ” $expr + $convert ì‚¬ìš©)
    age = filters.get("age")
    if age is not None:
        try:
            age_int = int(age)
            conditions.append({
                "$or": [
                    {"eligibility.age_min": "0"},  # ì—°ë ¹ ì œí•œ ì—†ìŒ
                    {
                        "$expr": {
                            "$let": {
                                "vars": {
                                    # ë¹„ì •ìƒ ê°’ì€ ë¹„êµì—ì„œ ì œì™¸ë˜ë„ë¡ sentinel ì‚¬ìš©
                                    "amin": {
                                        "$convert": {
                                            "input": "$eligibility.age_min",
                                            "to": "int",
                                            "onError": 999,
                                            "onNull": 999,
                                        }
                                    },
                                    "amax": {
                                        "$convert": {
                                            "input": "$eligibility.age_max",
                                            "to": "int",
                                            "onError": -1,
                                            "onNull": -1,
                                        }
                                    },
                                },
                                "in": {
                                    "$and": [
                                        {"$lte": ["$$amin", age_int]},
                                        {
                                            "$or": [
                                                {"$eq": ["$$amax", 0]},  # ìµœëŒ€ ë‚˜ì´ ì œí•œ ì—†ìŒ
                                                {"$gte": ["$$amax", age_int]},
                                            ]
                                        },
                                    ]
                                },
                            }
                        }
                    },
                ]
            })
        except (ValueError, TypeError):
            pass

    # ì§€ì—­ (region ìµœìƒìœ„ field - 'ì „êµ­' í¬í•¨)
    region = filters.get("region")
    if region and region != "all":
        conditions.append({
            "$or": [
                {"region": {"$in": [region]}},
                {"region": {"$in": ["ì „êµ­"]}},
            ]
        })

    # ì§ì—…ìƒíƒœ (job_type ìµœìƒìœ„ field - 'ì œí•œì—†ìŒ' í¬í•¨)
    job_status = filters.get("jobStatus")
    if job_status and job_status != "all":
        conditions.append({
            "$or": [
                {"job_type": {"$in": [job_status]}},
                {"job_type": {"$in": ["ì œí•œì—†ìŒ"]}},
            ]
        })

    # ë§ˆê°ì—¬ë¶€ (openOnly=true â†’ ëª¨ì§‘ì¤‘ì¸ ì •ì±…ë§Œ)
    open_only = filters.get("openOnly")
    if open_only:
        today_str = date.today().strftime("%Y%m%d")
        
        # ìƒˆë¡œìš´ ë³µí•© ì¡°ê±´ ë¡œì§
        # 1. apply_period_typeì´ "ë§ˆê°"ì´ë©´ ë¬´ì¡°ê±´ ì œì™¸
        # 2. apply_period_end ê°’ì´ ì˜¤ëŠ˜(<today_str)ë³´ë‹¤ ì‘ìœ¼ë©´(ê³¼ê±°ë©´) ì œì™¸
        # 3. apply_period ê°’ì´ ìˆê³  ì¢…ë£Œì¼ íŒŒì‹± ì‹œ ì˜¤ëŠ˜ë³´ë‹¤ ì‘ìœ¼ë©´ ì œì™¸
        # ìœ„ ì œì™¸ ì¡°ê±´ì„ ëš«ê³  ë‚¨ì€ ê²ƒë“¤ì„ ëª¨ì§‘ì¤‘ìœ¼ë¡œ ê°„ì£¼ 
        
        # MongoDB ì¿¼ë¦¬ êµ¬ì„±:
        # AND ì¡°ê±´:
        # A. apply_period_type != "ë§ˆê°"
        # B. OR ì¡°ê±´:
        #    B-1. apply_period_end >= ì˜¤ëŠ˜
        #    B-2. apply_period_end ì—†ê±°ë‚˜ ë¹„ì–´ ìˆê³ , apply_periodì—ì„œ íŒŒì‹±í•œ ë‚ ì§œê°€ >= ì˜¤ëŠ˜
        #    B-3. ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ìƒì‹œëª¨ì§‘ìœ¼ë¡œ ê°„ì£¼ (í†µê³¼)
        
        conditions.append({
            "$and": [
                # 1. ëª…ì‹œì  ë§ˆê° ì œì™¸
                {"dates.apply_period_type": {"$ne": "ë§ˆê°"}},
                
                # 2. ê¸°í•œ ì²´í¬ (OR ì¡°ê±´)
                {
                    "$or": [
                        # Case 1: apply_period_end í•„ë“œê°€ ìˆê³  ì˜¤ëŠ˜ ì´ìƒì¸ ê²½ìš°
                        {
                            "$and": [
                                {"dates.apply_period_end": {"$exists": True}},
                                {"dates.apply_period_end": {"$ne": ""}},
                                {"dates.apply_period_end": {"$gte": today_str}}
                            ]
                        },
                        # Case 2: apply_period (ë¬¸ìì—´) íŒŒì‹± í›„ ì˜¤ëŠ˜ ì´ìƒì¸ ê²½ìš°
                        {
                            "$and": [
                                {"dates.apply_period": {"$exists": True}},
                                {"dates.apply_period": {"$ne": ""}},
                                {
                                    "$expr": {
                                        "$gte": [
                                            {
                                                "$trim": {
                                                    "input": {
                                                        "$arrayElemAt": [
                                                            {"$split": ["$dates.apply_period", "~"]},
                                                            1
                                                        ]
                                                    }
                                                }
                                            },
                                            today_str
                                        ]
                                    }
                                }
                            ]
                        },
                        # Case 3: ê¸°í•œ ì •ë³´ê°€ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš° (ìƒì‹œëª¨ì§‘ìœ¼ë¡œ ê°„ì£¼)
                        {
                            "$and": [
                                {"$or": [{"dates.apply_period_end": {"$exists": False}}, {"dates.apply_period_end": ""}]},
                                {"$or": [{"dates.apply_period": {"$exists": False}}, {"dates.apply_period": ""}]}
                            ]
                        }
                    ]
                }
            ]
        })


    if not conditions:
        return {}
    if len(conditions) == 1:
        return conditions[0]
    return {"$and": conditions}


def _lookup_match_from_policy_match(match: dict, prefix: str = "policy_detail"):
    """
    ì¼ë°˜ í•„í„° ì¡°ê±´ì„ $lookup í›„ ì‚¬ìš©í•  ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if not match:
        return {}

    mapped = {}

    for key, value in match.items():
        if key.startswith("$"):
            if isinstance(value, list):
                mapped[key] = [_lookup_match_from_policy_match(item, prefix) for item in value]
            else:
                mapped[key] = value
        else:
            mapped[f"{prefix}.{key}"] = value

    return mapped


def _normalize_page(page: int, page_size: int):
    """
    í˜ì´ì§€ë„¤ì´ì…˜ ê°’ì„ ì•ˆì „í•œ ë²”ìœ„ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
    """
    page = max(1, int(page))
    page_size = min(100, max(1, int(page_size)))
    return page, page_size


# ============================================================================
# 3ï¸âƒ£ ë©”ì¸ ê²€ìƒ‰ í•¨ìˆ˜
# ============================================================================

def search_policies(query: str = "", filters: dict = None, page: int = 1, page_size: int = 20):
    """
    ì •ì±… ê²€ìƒ‰ ë©”ì¸ í•¨ìˆ˜
    - ê²€ìƒ‰ì–´ ì—†ìœ¼ë©´: í•„í„°ë§ëœ ì „ì²´ ëª©ë¡ ë°˜í™˜
    - ê²€ìƒ‰ì–´ ìˆìœ¼ë©´: Gemini ì„ë² ë”© + Vector Search (score >= SCORE_THRESHOLD)
    """
    page, page_size = _normalize_page(page, page_size)
    query = (query or "").strip()
    terms = _query_terms(query)

    print(f"DEBUG: ê²€ìƒ‰ ì‹œì‘ - query='{query}', filters={filters}, page={page}", flush=True)

    # ëª©ë¡ ëª¨ë“œ projection
    projection = {
        "_id": 1,
        "policy_id": 1,
        "policy_name": 1,
        "category": 1,
        "sub_category": 1,
        "policy_summary": 1,
        "content_chunk_v3": 1,
        "content": 1,
        "support_content": 1,
        "supervising_agency": 1,
        "dates": 1,
        "eligibility": 1,
        "application_url": 1,
        "earn": 1,
    }

    skip = (page - 1) * page_size
    base_match = _build_policy_match(filters)

    # â”€â”€ Case 1: ê²€ìƒ‰ì–´ ì—†ìŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not query:
        try:
            db = getMongoDbClient()
            policies_collection = db["policies"]

            total = policies_collection.count_documents(base_match)
            cursor = (
                policies_collection
                .find(base_match, projection)
                .sort("policy_name", 1)
                .skip(skip)
                .limit(page_size)
            )
            rows = list(cursor)
            for item in rows:
                item["_query_terms"] = terms
            results = [_enrich_policy_item(item) for item in rows]
        except Exception as e:
            return {"error": f"ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}

        return {
            "query": query,
            "filters": filters or {},
            "page": page,
            "page_size": page_size,
            "total": total,
            "results": results,
        }

    # â”€â”€ Case 2: ê²€ìƒ‰ì–´ ìˆìŒ (ë²¡í„° ê²€ìƒ‰) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        client = get_genai_client()
        response = client.models.embed_content(
            model="gemini-embedding-001",
            contents=query,
        )

        if hasattr(response, "embeddings"):
            query_embedding = response.embeddings[0].values
        elif hasattr(response, "embedding"):
            query_embedding = response.embedding.values
        else:
            query_embedding = response.get("embedding", {}).get("values")

    except Exception as e:
        print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return {"error": str(e)}

    try:
        db = getMongoDbClient()
    except Exception as e:
        return {"error": f"DB ì—°ê²° ì‹¤íŒ¨: {str(e)}"}

    # ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš© ì‹œ ì‹¤ì œ ê²°ê³¼ê°€ ì ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    # numCandidatesëŠ” ì¶©ë¶„íˆ í¬ê²Œ ìœ ì§€
    num_candidates = 858  # ì „ì²´ ë¬¸ì„œ ìˆ˜ ê¸°ì¤€

    vector_search_stage = {
        "index": "vector_index_v2",
        "path": "embedding_gemini_v2",
        "queryVector": query_embedding,
        "numCandidates": num_candidates,
        "limit": num_candidates,
    }

    pipeline = [
        {"$vectorSearch": vector_search_stage},
        # âœ… ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ì¶œ í›„ ì„ê³„ê°’ í•„í„°ë§ (0.80 ë¯¸ë§Œ ì œê±°)
        {"$addFields": {"search_score": {"$meta": "vectorSearchScore"}}},
        {"$match": {"search_score": {"$gte": SCORE_THRESHOLD}}},
        {
            "$lookup": {
                "from": "policies",
                "localField": "policy_id",
                "foreignField": "_id",
                "as": "policy_detail",
            }
        },
        {"$unwind": "$policy_detail"},
    ]

    if base_match:
        pipeline.append({"$match": _lookup_match_from_policy_match(base_match)})

    # í‚¤ì›Œë“œ ê²€ìƒ‰ ê°•í™”: ì‚¬ìš©ìê°€ ì…ë ¥í•œ queryê°€ í¬í•¨ëœ ì •ì±…(ì´ë¦„ ë˜ëŠ” í‚¤ì›Œë“œ)ì— ê°€ì¤‘ì¹˜ë¥¼ ì£¼ê±°ë‚˜ ê²°ê³¼ë¥¼ í•„í„°ë§
    # Vector Search ê²°ê³¼ ë‚´ì—­ì—ì„œ ëª…ì‹œì  í…ìŠ¤íŠ¸ ë§¤ì¹­ì´ ìˆëŠ” ê²½ìš°ë¥¼ ìƒë‹¨ìœ¼ë¡œ ëŒì–´ì˜¬ë¦¬ê±°ë‚˜ ë³‘í•©
    # í‚¤ì›Œë“œ ê²€ìƒ‰ ê°•í™”: ì‚¬ìš©ìê°€ ì…ë ¥í•œ queryê°€ í¬í•¨ëœ ì •ì±…ì— ê°€ì¤‘ì¹˜
    if query:
        pipeline.extend([
            {
                "$addFields": {
                    "text_match_bonus": {
                        "$cond": {
                            "if": {
                                "$or": [
                                    {"$regexMatch": {"input": "$policy_detail.policy_name", "regex": query, "options": "i"}},
                                    {"$regexMatch": {"input": {"$ifNull": ["$policy_detail.keywords", ""]}, "regex": query, "options": "i"}}
                                ]
                            },
                            "then": 0.5,
                            "else": 0
                        }
                    }
                }
            },
            {
                "$addFields": {
                    "final_score": {"$add": ["$search_score", "$text_match_bonus"]}
                }
            }
        ])

    # ğŸ’¡ ë©”ëª¨ë¦¬ í•œë„ ì´ˆê³¼(32MB ì œí•œ)ë¥¼ ë§‰ê¸° ìœ„í•´ ì •ë ¬($sort) ì „ì— ë¶ˆí•„ìš”í•œ í° ë°ì´í„°(content ë“±)ë¥¼ ë¯¸ë¦¬ $projectë¡œ ì œê±°í•©ë‹ˆë‹¤.
    pipeline.extend([
        {
            "$project": {
                "_id": 0,
                "policy_id": "$policy_detail.policy_id",
                "doc_id": {"$toString": "$policy_detail._id"},
                "policy_name": "$policy_detail.policy_name",
                "category": "$policy_detail.category",
                "sub_category": "$policy_detail.sub_category",
                "policy_summary": "$policy_detail.policy_summary",
                "content_chunk_v3": {
                    "$ifNull": ["$policy_detail.content_chunk_v3", "$content_chunk_v3"]
                },
                "content": "$policy_detail.content",
                "support_content": "$policy_detail.support_content",
                "supervising_agency": "$policy_detail.supervising_agency",
                "dates": "$policy_detail.dates",
                "eligibility": "$policy_detail.eligibility",
                "application_url": "$policy_detail.application_url",
                "earn": "$policy_detail.earn",
                "search_score": 1,
                "final_score": {"$ifNull": ["$final_score", "$search_score"]} # queryê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„
            }
        }
    ])

    if query:
        # queryê°€ ìˆì„ ë•ŒëŠ” ê³„ì‚°ëœ final_score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        pipeline.append({
            "$sort": {"final_score": -1}
        })
    else:
        # queryê°€ ì—†ìœ¼ë©´ (ë²¡í„° ê²€ìƒ‰ ë¯¸ìˆ˜í–‰ ì‹œ) ì´ë¦„ìˆœ ì •ë ¬
        pipeline.append({
            "$sort": {"policy_name": 1}
        })

    pipeline.extend([
        {
            "$facet": {
                "meta": [{"$count": "total"}],
                "items": [{"$skip": skip}, {"$limit": page_size}],
            }
        }
    ])

    try:
        aggregated = list(db["policy_vectors"].aggregate(pipeline, allowDiskUse=True))
        payload = aggregated[0] if aggregated else {"meta": [], "items": []}
        total = payload["meta"][0]["total"] if payload["meta"] else 0
        rows = payload["items"]
        for item in rows:
            item["_query_terms"] = terms
        results = [_enrich_policy_item(item) for item in rows]
        print(f"DEBUG: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ total={total} (score>={SCORE_THRESHOLD})", flush=True)
    except Exception as e:
        print(f"ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {"error": f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"}

    return {
        "query": query,
        "filters": filters or {},
        "page": page,
        "page_size": page_size,
        "total": total,
        "results": results,
    }
